# Spoken Language Understanding (SLU) for Task-Oriented Dialogue

![Python Version](https://img.shields.io/badge/python-3.10+-blue.svg)
![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)
[![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://archeltaneka-slot-filling-intent-detection-app-vcbymi.streamlit.app/)
![Tests](https://github.com/archeltaneka/slot-filling-intent-detection/actions/workflows/main.yml/badge.svg)

## ğŸ“ƒ Overview

This repository contains an end-to-end Spoken Language Understanding (SLU) production-ready pipeline for Joint Intent Detection and Slot Filling. This project implements multiple architectures from CRF baselines to Joint BiLSTM and BERT-based models, integrated with a Streamlit interface and automated CI/CD. The system performs two tasks simultaneously:

- Intent Classification: Determining what the user wants to do (e.g., flight query).
- Slot Filling: Identifying key entities in the sentence (e.g., origin, destination, date, etc.).

ğŸ”— Live App: https://archeltaneka-slot-filling-intent-detection-app-vcbymi.streamlit.app/

## ğŸš€ Features

- Joint Modeling: Simultaneously predicts intents and slot labels using shared representations.
- Multiple Architecture Comparisons:
    - Baseline: CRF (Slots) + Random Forest (Intent).
    - Neural: BiLSTM and BiLSTM-Attention with GloVe embeddings.
    - Transformer: Joint-BERT fine-tuning using HuggingFace.
- Robust Pipeline: Custom data loaders, feature engineers, and group-aware data splitters.
- Production Quality: Automated unit testing suite and GitHub Actions CI/CD pipeline.

## ğŸ› ï¸Tech Stack

- Python
- Streamlit
- NumPy
- Scikit-learn
- PyTorch
- Transformers
- HuggingFace

## ğŸ“ƒRequirements

- Python 3.10+

## ğŸ“¦Installation & Setup

1. Clone the repo

```{bash}
git clone https://github.com/archeltaneka/slot-filling-intent-detection.git
cd slot-filling-intent-detection
```

2. Install dependencies

```{bash}
pip install -r requirements.txt
```

3. Run Streamlit app locally

```{bash}
streamlit run app.py
```

## ğŸ“Š Training/Experimenting Models

To run the full training pipeline (Baseline, BiLSTM, and BERT):

```{bash}
python train.py
```

Training artifacts (model weights and vocabularies) will be saved to files/checkpoints/.

To experiment with different hyperparameters, modify the config files `config.yaml`

```
# config.yaml
...
embed_dim: 100
hidden_dim: 256
num_layers: 5
dropout: 0.5
```

Then rerun the training pipeline `train.py`

## ğŸ§ª Testing

We maintain high code quality through automated testing and continuous integration.

- Unit Testing (WIP): Comprehensive tests for data-processing modules (Splitter, Builder, Feature Engineer) using pytest.
- Automated Workflow: GitHub Actions runs the test suite on every Pull Request to ensure no regressions.
- Test Coverage (WIP): We are currently integrating Codecov to track test coverage and identify untested code paths.

## ğŸ›  Project Structure

```
slot-filling-intent-detection/
â”œâ”€â”€ data/                      # Raw data files
â”œâ”€â”€ files/
â”‚   â”œâ”€â”€ checkpoints/           # Saved model checkpoints
â”‚   â””â”€â”€ embedding/             # Created when training models
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ builder.py          # Transform raw data 
â”‚   â”‚   â”œâ”€â”€ data_utils.py       # Data processing utilities
â”‚   â”‚   â”œâ”€â”€ feature_engineer.py # Feature engineer transformed data
â”‚   â”‚   â”œâ”€â”€ loader.py           # Data loader
â”‚   â”‚   â””â”€â”€ splitter.py         # Data splitter using group-aware splitter
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ baseline.py         # CRF baseline model
â”‚   â”‚   â”œâ”€â”€ model_utils.py      # Model utilities
â”‚   â”‚   â”œâ”€â”€ models.py           # Joint BILSTM and BERT models
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ train_utils.py      # Model training utilities
â”‚   â”‚   â”œâ”€â”€ trainer.py          # Model trainer
â”‚   â””â”€â”€ __init__.py
â”‚   â””â”€â”€ evaluation.py           # Model evaluation
â”‚   â””â”€â”€ inference.py            # Model inference
â”‚   â””â”€â”€ pipeline.py             # Data transformation pipeline
â”‚   â””â”€â”€ utils.py                # General utilities
â”œâ”€â”€ tests/
â”œâ”€â”€ app.py                      # Streamlit web app
â”œâ”€â”€ config.yaml                 # Model configuration file
â”œâ”€â”€ download_models.py          # Download pre-trained models
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ train.py                    # Training script
```

## ğŸ¿Demo Video
[streamlit-app-2026-01-19-19-36-04.webm](https://github.com/user-attachments/assets/b507bb2e-02a8-4a82-b31d-9423095efb7b)

## ğŸ“„ License

MIT License Â© 2025 Archel Taneka

## âš™ï¸ Want to contribute?

PRs, suggestions, and issues are welcome.

